<?xml version="1.0" encoding="UTF-8"?>
<!-- 
	This is the configuration file for the Social Network Connector.
	It configures low level startup parameter - like the crawlers to run.
	To configure the runtime behavior of the SNC, take a look at 
	* SNC_Runtime_Configuration.xml		- for general runtime configuration options
	* SNC_Crawler_Configuration			- for the constraints to the crawler
	* SNC_HANA_Configuration.xml		- for the hana coonfiguration 
	* Administration-servlet.xml		- for the web administration servlet
	* web.xml							- for general web configuration
	* log4j.xml							- for logging options


	Licensed to the Apache Software Foundation (ASF) under one or more contributor 
	license agreements. See the NOTICE file distributed with this work for additional 
	information regarding copyright ownership. The ASF licenses this file to 
	You under the Apache License, Version 2.0 (the "License"); you may not use 
	this file except in compliance with the License. You may obtain a copy of 
	the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required 
	by applicable law or agreed to in writing, software distributed under the 
	License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS 
	OF ANY KIND, either express or implied. See the License for the specific 
	language governing permissions and limitations under the License. 
-->
<!-- @version $Id: applicationContext.xml 561608 2007-08-01 00:33:12Z vgritsenko $ -->

<beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p"
	xmlns:context="http://www.springframework.org/schema/context"
	xmlns:util="http://www.springframework.org/schema/util"
	xmlns:jdbc="http://www.springframework.org/schema/jdbc" xmlns:tx="http://www.springframework.org/schema/tx"
	xsi:schemaLocation="http://www.springframework.org/schema/beans 
                           http://www.springframework.org/schema/beans/spring-beans.xsd
                           http://www.springframework.org/schema/context 
                           http://www.springframework.org/schema/context/spring-context.xsd
                           http://www.springframework.org/schema/jdbc 
                           http://www.springframework.org/schema/jdbc/spring-jdbc.xsd
                           http://www.springframework.org/schema/tx
                           http://www.springframework.org/schema/tx/spring-tx.xsd
                           http://www.springframework.org/schema/util 
                           http://www.springframework.org/schema/util/spring-util.xsd">
                           
	<context:annotation-config />
		<context:component-scan base-package="de.comlineag.snc.appstate" />
		<context:component-scan base-package="de.comlineag.snc.constants" />
		<context:component-scan base-package="de.comlineag.snc.crypto" />
		<context:component-scan base-package="de.comlineag.snc.data" />
		<context:component-scan base-package="de.comlineag.snc.handler" />
		<context:component-scan base-package="de.comlineag.snc.helper" />
		<context:component-scan base-package="de.comlineag.snc.job" />
		<context:component-scan base-package="de.comlineag.snc.neo4j" />
		<context:component-scan base-package="de.comlineag.snc.persistence" />
	<tx:annotation-driven />
	
	<bean id="contextApplicationContextProvider" class="de.comlineag.snc.appstate.ApplicationContextProvider"></bean>
	
	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
	     J O B    C O N T R O L    S E T T I N G S  -  J O B    C O N T R O L    S E T
	     this is the section in which to turn on/off the different crawler 
	     - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->
	     <!-- Activate Spring annotation support -->
	<bean class="org.springframework.scheduling.quartz.SchedulerFactoryBean">
		<property name="autoStartup"><value>true</value></property>
		<property name="overwriteExistingJobs"><value>true</value></property>
		<property name="waitForJobsToCompleteOnShutdown"><value>false</value></property>

		<property name="quartzProperties">
			<props>
				<!-- ThreadPool -->
				<prop key="org.quartz.threadPool.class">org.quartz.simpl.SimpleThreadPool</prop>
				<prop key="org.quartz.threadPool.threadCount">5</prop>
			</props>
		</property>
		<property name="triggers">
			<list>
				<!-- SOCIAL NETWORK CRAWLER
					activate each crawler you want the SNC to scan through. 
					Make sure to set the threadCount number above according to the number of activated 
					crawlers. The total number of threads must include the number of actual crawlers in
					this section plus the FsCrawler below and the GeneralConfgurationTrigger - resulting 
					in number of crawlers plus 2 as the threadcount -->
				<ref bean="TwitterCrawlerTrigger" />
				<!-- <ref bean="FacebookCrawlerTrigger"/> -->
				<!-- <ref bean="GoogleCrawlerTrigger"/> -->
				<!-- <ref bean="LinkedinCrawlerTrigger"/> -->
				<!-- <ref bean="MultiWebCrawlerTrigger"/> -->
				<ref bean="SimpleWebCrawlerTrigger"/>
				<ref bean="LithiumCrawlerTrigger" />
				
				
				<!-- FILESYSTEM CRAWLER - SAFEGUARD
					this is the fail save crawler. It scans through a backup directory (typically ./json)
					and retries to insert/update all posts and users (stored within there as json files)
					into the actual persistence manager (e.g. HANA or Neo4J. It is therefore a save guard
					for the runtime environment of the social network connector. 
					You should only deactivate it in case you do not save the posts and users of failed
					inserts in a backup directory (can be configured in SNC_Runtime_Configuration.xml), 
					in which case there would be no sense scanning :-) -->
				<!-- <ref bean="FsCrawlerTrigger" /> -->
				
				<!-- RUNTIME CONFIGURATION
					this is the basic configuration for the social network connector if you deactivate it,
					the SNC will cease to function as no information regarding the runtime environment
					of the SNC can be retrieved by the other components of the SNC -->
				<ref bean="RuntimeConfigurationTrigger" />
			</list>
		</property>
	</bean>
	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
	     END OF JOB CONTROL SECTION - END OF JOB CONTROL SECTION - END OF JOB CONTROL
	     - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->
	
	
	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
	     C R A W L E R    S E T T I N G S  -  C R A W L E R    S E T T I N G S  -  C R                                              
	     YOU NORMALLY DO NOT NEED TO ACTIVATE/DEACTIVATE A CRAWLER HERE, BUT YOU MAY 
		 NEED TO ADAPT KEYS AND THE LIKE. FOR EXAMPLE, TWITTER USES KEYS TO AUTHORIZE
		 THE CRAWLER (FACEBOOK ALSO) AND LITHIUM, ON THE OTHER HAND, MAY NEED TO GET THE
		 URL AND SERVER NAME ETC. ADAPTED.
	     - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->
	
	<!-- T W I T T E R    C R A W L E R    (WORKS)		-->
	<bean name="TwitterCrawlerDetail"
		class="org.springframework.scheduling.quartz.JobDetailFactoryBean">
		<property name="jobClass" value="de.comlineag.snc.job.TwitterCrawler" />
		<!-- <property name="concurrent" value="false" /> -->
		<property name="durability" value="true" />
		<property name="jobDataAsMap">
			<map>
				<!-- THIS MUST BE SET ACCORDING TO AN EXISTING CODE FOR A SOCIAL NETWORK ENTRY IN SNC_Runtime_Configuration.xml -->
				<entry key="SN_ID_CODE" value="TW" />
				
				<!-- These are the security tokens for the twitter API -->
				<entry key="consumerKey" value="zlGuAavBH2T23hIm57l8WA" />
				<entry key="consumerSecret" value="xzqH6lLWnXLvlHJooNDaCDXlzJzv976JcWt8y2eyHBk" />
				<entry key="token" value="754994-KDec8qJBwEggHwHQ9XO0X7QBx1VCOZwgbgtpYiibWjl" />
				<entry key="tokenSecret" value="qm1dqrJas8Lf2ANU8Lx470TkcUSndWLwvJ1I2huZKvJrc" />
			</map>
		</property>
	</bean>
	<bean id="TwitterCrawlerTrigger"
		class="org.springframework.scheduling.quartz.SimpleTriggerFactoryBean">
		<property name="jobDetail" ref="TwitterCrawlerDetail" />
		<!-- 1 second delay after startup -->
		<property name="startDelay" value="1000" />
		<!-- repeat the job every 
							5000 - 50 seconds 
							6000 - 1 minutes 
							15000 - 2,5 minutes (round about) 
							30000 - 5 minutes -->
		<property name="repeatInterval" value="30000" />
	</bean>
	
	
	<!-- L I T H I U M    C R A W L E R    (WORKS) -->
	<bean name="LithiumCrawlerDetail"
		class="org.springframework.scheduling.quartz.JobDetailFactoryBean">
		<property name="jobClass" value="de.comlineag.snc.job.LithiumCrawler" />
		<!-- <property name="concurrent" value="false" /> -->
		<property name="durability" value="true" />
		<property name="jobDataAsMap">
			<map>
				<!-- THIS MUST BE SET ACCORDING TO AN EXISTING CODE FOR A SOCIAL NETWORK ENTRY IN SNC_Runtime_Configuration.xml -->
				<entry key="SN_ID_CODE" value="CC" />
				
				<!-- These are security tokens - not used -->
				<entry key="consumerKey" value="" />
				<entry key="consumerSecret" value="" />
				<entry key="token" value="" />
				<entry key="tokenSecret" value="" />
				
				<!-- login settings - are encrypted using base64 -->
				<entry key="user" value="Y21yYWw=" />			<!-- cmral -->
				<entry key="passwd" value="MTIzVGVzdDEyMw==" />	<!-- 123Test123 -->
				
				<!-- with these entries the url to the communities' rest api is generated -->
				<entry key="protocol" value="https" />
				<entry key="port" value="443" />
				<entry key="server_url" value="wissen.cortalconsors.de" />
				<entry key="rest_api_loc" value="/restapi/vc" />
			</map>
		</property>
	</bean>
	<bean id="LithiumCrawlerTrigger"
		class="org.springframework.scheduling.quartz.SimpleTriggerFactoryBean">
		<property name="jobDetail" ref="LithiumCrawlerDetail" />
		<property name="startDelay" value="2000" />
		<property name="repeatInterval" value="300000" />
	</bean>
	
	
	<!-- S I M P L E    W E B    C R A W L E R    (IN DEVELOPMENT) -->
	<!-- this is the simplest way of crawling a webpage. It has significant disadvantages to the MultiWebCrawler
		 and should only be used in the most simple environment. First of all, you have to setup the url to crawl
		 within this file, rather than in the crawler configuration file. Second you can only pass one webpage/domain
		 as a starting point. And finally, it is very cumbersome to use an individual SN_ID (social network) code
		 for each page. Because of these three points, I recommend to opt for MultiWebCrawler instead of SimpleWebCrawler. 
		 But nevertheless, it works and you can use it :-) -->
	<bean name="SimpleWebCrawlerDetail"
		class="org.springframework.scheduling.quartz.JobDetailFactoryBean">
		<property name="jobClass" value="de.comlineag.snc.job.SimpleWebCrawler" />
		<property name="durability" value="true" />
		<property name="jobDataAsMap">
			<map>
				<!-- THIS MUST BE SET ACCORDING TO AN EXISTING CODE FOR A SOCIAL NETWORK ENTRY IN SNC_Runtime_Configuration.xml -->
				<entry key="SN_ID_CODE" value="WC" />
				
				<!-- set the starting url and maximum number of links to follow
				<entry key="server_url" value="https://www.wallstreet-online.de/community" />
				 -->
				<entry key="server_url" value="http://www.netmoms.de" />
				
				<!-- if you set this higher then the value of SEARCH_LIMIT in SNC_Runtim_Configuration then that value will be used 
					 as the value in the runtime configuration acts as a safety margin to not exceed a certain scanning depth. -->
				<entry key="max_depth" value="100" />
				
				<!-- whether or not the crawler is allowed to follow links off of the initial domain 
					 If set to true, then the crawler is NOT allowed to fetch pages from a new domain.
					 It is generally not recommended to set this to false (thus allowing to leave the 
					 domain) AND have a high value in max_depth, as this could lead to a lot of pages 
					 being downloaded from any place on the net just by following some nice linklist 
					 one has setup on his/her page  -->
				<entry key="stayOnDomain" value = "true" /> 
				
				<!-- if the website requires an authentication, set username and password here -->
				<!-- <entry key="user" value="Y29taW5lMjAxNA==" /> -->		<!-- comine2014 -->
				<!-- <entry key="passwd" value="TUd1LTZ0Yy1BUjUtdTdS" /> --> <!-- MGu-6tc-AR5-u7R -->
			</map>
		</property>
	</bean>
	<bean id="SimpleWebCrawlerTrigger"
		class="org.springframework.scheduling.quartz.SimpleTriggerFactoryBean">
		<property name="jobDetail" ref="SimpleWebCrawlerDetail" />
		<property name="startDelay" value="2000" />
		<property name="repeatInterval" value="30000000" />
	</bean>
	
	
	<!-- M U L T I P L E    P A G E S    W E B    C R A W L E R    (SKELETON) -->
	<bean name="MultiWebCrawlerDetail"
		class="org.springframework.scheduling.quartz.JobDetailFactoryBean">
		<property name="jobClass" value="de.comlineag.snc.job.MultiWebCrawler" />
		<property name="durability" value="true" />
		<property name="jobDataAsMap">
			<map>
				<!-- other than with the SimpleWebCrawler, the MultiWebCrawler can concurrently crawl multiple pages 
					 therefore, all that he needs to know during startup is, where it's own configuration file is 
					 in this file the different pages together with authentication options can be defined.
					 I recommend to create a new configuration file with every new customer. 
					 
					 You can also put the web crawler specific configuration in the general configuration file specified
					 in bean configurationManager (see below). In this case you MUST enter see_general_crawler_config
					 in exactly this writing in the value for the configuration file here. If you do that, of course you 
					 have to setup the pages and sites in the other configuration file. Examples are provided in the
					 templates.
					 -->
				<entry key="configurationFile" value="webapp/WEB-INF/SNC_CrawlerConfiguration/HippWebCrawlerConfiguration.xml" />
				<entry key="server_url" value="www.windeln.de" />
			</map>
		</property>
	</bean>
	<bean id="MultiWebCrawlerTrigger"
		class="org.springframework.scheduling.quartz.SimpleTriggerFactoryBean">
		<property name="jobDetail" ref="MultiWebCrawlerDetail" />
		<property name="startDelay" value="2000" />
		<property name="repeatInterval" value="30000000" />
	</bean>
	
	<!-- F A C E B O O K    C R A W L E R    (TO BE IMPLEMENTED) -->
	<bean name="FacebookCrawlerDetail"
		class="org.springframework.scheduling.quartz.JobDetailFactoryBean">
		<property name="jobClass" value="de.comlineag.snc.job.Facebook4JFbCrawler" />
		<!-- <property name="concurrent" value="false" /> -->
		<property name="durability" value="true" />
		<property name="jobDataAsMap">
			<map>
				<!-- THIS MUST BE SET ACCORDING TO AN EXISTING CODE FOR A SOCIAL NETWORK ENTRY IN SNC_Runtime_Configuration.xml -->
				<entry key="SN_ID_CODE" value="FB" />
				
				<!-- These are security tokens -->
				<entry key="appId" value="1375488886009208" />
				<entry key="appSecret" value="1d8ff81333b5dc9ba6ef0de228dfb130" />
				<entry key="accessToken" value="1375488886009208|1d8ff81333b5dc9ba6ef0de228dfb130" />
				<entry key="permissionSet" value="" />
				
				<!-- with these entries the url to the rest api and graph engine is generated -->
				<entry key="protocol" value="https" /> 					<!-- the access protocol -->
				<entry key="port" value="443" /> 						<!-- the port to use -->
				<entry key="server_url" value="graph.facebook.com" /> 	<!-- the actual host -->
				<entry key="location" value="" /> 						<!-- an addition to the host part of the location -->
			</map>
		</property>
	</bean>
	<bean id="FacebookCrawlerTrigger"
		class="org.springframework.scheduling.quartz.SimpleTriggerFactoryBean">
		<property name="jobDetail" ref="FacebookCrawlerDetail" />
		<!-- 1 second delay after startup -->
		<property name="startDelay" value="1000" />
		<!-- repeat the job every 
							5000 - 50 seconds 
							6000 - 1 minutes 
							15000 - 2,5 minutes (round about) 
							30000 - 5 minutes -->
		<property name="repeatInterval" value="30000" />
	</bean>
	
	
	<!-- G O O G L E    C R A W L E R    (TO BE DEFINED) -->
<!--  
	<bean name="GoogleCrawlerDetail" class="org.springframework.scheduling.quartz.JobDetailFactoryBean"> 
		<property name="jobClass" value="de.comlineag.snc.job.GoogleCrawler" /> 
		<property name="concurrent" value="false" />
		<property name="durability" value="true" />
		<property name="jobDataAsMap">
			<map> 
				<entry key="SN_ID_CODE" value="GP" />
				
				<entry key="consumerKey" value="" /> 
				<entry key="consumerSecret" value="" /> 
				<entry key="token" value="" /> 
				<entry key="tokenSecret" value="" /> 
				
				<entry key="user" value="" /> 
				<entry key="passwd" value="" /> 
				
				<entry key="protocol" value="https" /> 
				<entry key="port" value="443" /> 
				<entry key="server_url"	value="google.com" /> 
				<entry key="graph_api_loc" value="/graph" /> 
				<entry key="rest_api_loc" value="/restapi/" /> 
			</map> 
		</property> 
	</bean> 
	<bean id="GoogleCrawlerTrigger" class="org.springframework.scheduling.quartz.SimpleTriggerFactoryBean"> 
		<property name="jobDetail" ref="GoogleCrawlerDetail" />
		<property name="startDelay" value="1000" />
		<property name="repeatInterval" value="30000" /> 
	</bean> 
-->
	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
	     END OF CRAWLER SECTION - END OF CRAWLER SECTION - END OF CRAWLER SECTION - EN 
	     - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->
	
	
	
	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
	     C O N F I G U R A T I O N    S E T T I N G S  -  C O N F I G U R A T I O N  S    
	     You may choose exactly one of the provided configuration manager 
	     - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->
	
	<!-- this is the bean to get the crawler configuration from the HANA (TO BE IMPLEMENETED) -->
	<!-- 
	<bean id="configurationManager" class="de.comlineag.snc.persistence.HANAConfigurationPersistence"> 
		<property name="protocol" value="http" /> 
		<property name="host" value="192.168.131.30" /> 
		<property name="port" value="8000" /> 
		<property name="jdbcPort" value="30015" /> 
		
		<property name="location" value="/comline/snc/services" /> 
		<property name="user" value="U0JNX0VYVA==" /> 
		<property name="pass" value="TW9uIzRwb3Mhc29DSUFM" /> 
	</bean> 
	-->

	<!-- this is the bean to get the crawler configuration specific for individual customers AND/OR domains from an xml file
		(WORKS AND PROVIDES THE ABILITY TO SETUP DIFFERENT CRAWLER CONFIGURATIONS FOR EITHER CUSTOMER OR DOMAIN) -->
 
	<bean id="configurationManager" class="de.comlineag.snc.persistence.ComplexXmlConfigurationPersistence"> 
		<property name="configDbHandler" value="webapp/WEB-INF/SNC_Crawler_Configuration/HippSpecificCrawlerConfiguration.xml" />
	</bean> 
	
	<!-- this is the bean to get the crawler configuration from a simple xml file 
		(WORKS BUT NO CUSTOMER SPECIFIC CONFIGURATION POSSIBLE)	-->
<!-- 
	<bean id="configurationManager" class="de.comlineag.snc.persistence.SimpleXmlConfigurationPersistence"> 
		<property name="configDbHandler" value="webapp/WEB-INF/SNC_Crawler_Configuration/SimpleCrawlerConfiguration.xml" /> 
	</bean>
-->
	 
	<!-- this is the bean to get the crawler configuration from an ini file 
		(WORKS WITH RESTRICTIONS - NO CUSTOMER AND NO CRAWLER SPECIFIC CONFIGURATION POSSIBLE) -->
<!-- 
	<bean id="configurationManager" class="de.comlineag.snc.persistence.IniFileConfigurationPersistence">
		<property name="configDbHandler" value="webapp/WEB-INF/SNC_Crawler_Configuration/CrawlerConfiguration.ini" />
	</bean>
 -->
	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
	     END OF CONFIGURATION SECTION - END OF CONFIGURATION SECTION - END OF CONFIGUR 
	     - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->
	
	
	
	
	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
	     P E R S I S T E N C E    S E T T I N G S  -  P E R S I S T E N C E    S E T T
	     You may choose exactly one of the provided persistence manager 
	     - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->
	
	<!-- F I L E S Y S T E M    J S O N    P E R S I S T E N C E    (WORKS)  
	     This one simply stores all posts and users as json files on disk. It is mainly 
	     thought of as a development and not as a runtime persistence manager. It uses 
	     the same path options as the FailSavePersistence (which is automatically started
	     in case a more sophisticated persistence manager, such as a DB, fails to store or 
	     update posts and users) and as such does not need any options. All options, like
	     the path to the directory, is taken from SNC_Runtime_Configuration.xml.
	     If you activate this storage manager, you should DEFINATELY turn off the FsCrawler 
	     in the Job control section, otherwise your system will end up storing and restoring
	     the same objects as json files with no end in sight -->
	<!-- 
	<bean id="persistenceManager" class="de.comlineag.snc.persistence.JsonFilePersistence" /> 
	-->
	
	<!-- H A N A    P E R S I S T E N C E    (WORKS) 
		 The SAP HANA InMemory DB persistence can be used via JDBC or OData. As such,
		 both options are set in this section. The properties for user and password
		 need to be crypted in the format as specified in the crypto section for
		 configuration options, called Configuration Crypto Settings. That means, if
		 you used Base64 to encode your login options for the db, activate the Base64 
		 crypto provider below.
		 
		 If you activate the HANA persistence manager, make sure to also activate 
		 the FsCrawler in the job control section. In case HANA is unable to store your 
		 data or the crawler is unable to connect to HANA, a FailSavePersistcenManager 
		 is activated, which stores all failed objects as json file on disk. The FsCrawler 
		 is used to scan the storage directory for failed objects and then tries to 
		 insert them in the HANA DB. -->
	<!-- -->
	<bean id="persistenceManager" class="de.comlineag.snc.persistence.HANAPersistence">
		<property name="host" value="192.168.131.30" />
		<property name="port" value="8000" />
		<property name="jdbcPort" value="30015" />
		<property name="protocol" value="http" />
		<property name="dbDriver" value="com.sap.db.jdbc.Driver" />
		<property name="location" value="/comline/saa/services" />
		<property name="serviceUserEndpoint" value="saveUser.xsodata" />
		<property name="servicePostEndpoint" value="savePost.xsodata" />
		<property name="user" value="U0JNX0VYVA==" />
		<property name="pass" value="TW9uIzRwb3Mhc29DSUFM" />
	</bean>
	 
	 
	<!-- C O U C H D B    P E R S I S T E N C E    (in progress) -->
	<!-- 
	<bean id="persistenceManager" class="de.comlineag.snc.persistence.CouchDbPersistence">
		<property name="host" value="localhost" />
		<property name="port" value="8000" />
		<property name="protocol" value="http" />
		<property name="location" value="/comline/saa/services" />
		<property name="serviceUserEndpoint" value="saveUser.xsodata" />
		<property name="servicePostEndpoint" value="savePost.xsodata" />
		<property name="user" value="admin" />
		<property name="pass" value="admin1234" />
	</bean>
	 -->
	
	<!-- R I A K - D B    P E R S I S T E N C E    (in progress) -->
	<!-- 
	<bean id="persistenceManager" class="de.comlineag.snc.persistence.RiakDbPersistence">
		<property name="host" value="localhost" />
		<property name="port" value="8000" />
		<property name="protocol" value="http" />
		<property name="location" value="/comline/saa/services" />
		<property name="serviceUserEndpoint" value="saveUser.xsodata" />
		<property name="servicePostEndpoint" value="savePost.xsodata" />
		<property name="user" value="admin" />
		<property name="pass" value="admin1234" />
	</bean>
	-->
	 
	<!-- N E O 4 J    P E R S I S T E N C E    (WORKS in part) -->
	<!-- 
	<bean id="persistenceManager" class="de.comlineag.snc.persistence.Neo4JPersistence"> 
		<property name="protocol" value="http" /> 
		<property name="host" value="localhost" /> 
		<property name="port" value="7474" /> 
		<property name="location" value="/db/data" /> 
		<property name="db_path" value="/db/data" /> 
	</bean> 
	-->
	
	<!-- N E O 4 J    E M B E D D E D    P E R S I S T E N C E    (TO BE IMPLEMENETED) -->
	<!--
	<bean id="persistenceManager" 
		class="de.comlineag.snc.persistence.Neo4JEmbeddedPersistence"> 
		<property name="protocol" value="t.b.d." /> 
		<property name="host" value="localhost" /> 
		<property name="port" value="7474" /> 
		<property name="location" value="/db/data" /> 
		<property name="db_path" value="/db/data" /> 
	</bean> 
	-->

	<!-- M A P D B    P E R S I S T E N C E    (TO BE IMPLEMENTED) -->
	<!-- 
	<bean id="persistenceManager" class="de.comlineag.snc.persistence.MapDBPersistence"> 
		<property name="protocol" value="t.b.d." /> 
		<property name="host" value="localhost"	/> 
		<property name="port" value="t.b.d." /> 
		<property name="location" value="/db/data" /> 
		<property name="db_path" value="/db/data" /> 
	</bean> 
	-->
	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
	     END OF PERSISTENCE SECTION - END OF PERSISTENCE SECTION - END OF PERSISTENCE  
	     - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->
	
	
	
	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
	     C R Y P T O    S E T T I N G S  -  C R Y P T O    S E T T I N G S  -  C R Y P   
	     You can choose exactly one of the available crypto provider for each category (id) 
	     - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->
	
	<!-- C O N F I G U R A T I O N     C R Y P T O     S E T T I N G S 
		 used to encrypt configuration settings for the persistence connection --> 
	<!-- NULL   Crypto Provider   -   this is the bean to set the configuration encryption provider to null -->
	<!-- <bean id="configurationCryptoProvider" class="de.comlineag.snc.crypto.NullCryptoProvider"> </bean> -->
	
	<!-- BASE64 Crypto Provider   -   this is the bean to set the configuration encryption provider to Base64 -->
	<bean id="configurationCryptoProvider" class="de.comlineag.snc.crypto.Base64CryptoProvider"> </bean>
	
	<!-- DES    Crypto Provider   -   this is the bean to set the configuration encryption provider to DES -->
	<!-- <bean id="configurationCryptoProvider" class="de.comlineag.snc.crypto.DesCryptoProvider"> </bean> -->
	
	<!-- 3DES   Crypto Provider   -   this is the bean to set the configuration encryption provider to Triple DES -->
	<!-- <bean id="configurationCryptoProvider" class="de.comlineag.snc.crypto.Des3CryptoProvider"> </bean> -->
	
	<!-- AES    Crypto Provider   -   this is the bean to set the configuration encryption provider to AES -->
	<!-- <bean id="configurationCryptoProvider" class="de.comlineag.snc.crypto.AesCryptoProvider"> </bean> -->
	
	
	<!-- D A T A     C R Y P T O     S E T T I N G S
		 used to encrypt/decrypt the data within the persistence (DB) - has nothing to do with the configuration -->
	<!-- NULL   Crypto Provider   -   this is the bean to set the data encryption provider to null - recommended -->
	<bean id="dataCryptoProvider" class="de.comlineag.snc.crypto.NullCryptoProvider"> </bean>
	
	<!-- BASE64 Crypto Provider   -   this is the bean to set the data encryption provider to Base64 -->
	<!-- <bean id="dataCryptoProvider" class="de.comlineag.snc.crypto.Base64CryptoProvider"> </bean> -->
	
	<!-- DES    Crypto Provider   -   this is the bean to set the data encryption provider to DES -->
	<!-- <bean id="dataCryptoProvider" class="de.comlineag.snc.crypto.DesCryptoProvider"> 
			<property name="initialVector"dfhjhgcfngcfhcecf4tcdgc5vtrgvhtdzvcgcdbzvt5cxhvxtycsvtsctyvzs5zcc5zzvhcdht></property>
		</bean> 
	-->
	
	<!-- 3DES   Crypto Provider   -   this is the bean to set the data encryption provider to Triple DES -->
	<!-- <bean id="dataCryptoProvider" class="de.comlineag.snc.crypto.Des3CryptoProvider"> </bean> -->
	
	<!-- AES    Crypto Provider   -   this is the bean to set the data encryption provider to AES -->
	<!-- <bean id="dataCryptoProvider" class="de.comlineag.snc.crypto.AesCryptoProvider"> </bean> -->
	
	
	<!-- S E A R C H     C R Y P T O     S E T T I N G S
		 used to encrypt/decrypt the search constraints from the crawler configuration -->
	<!-- NULL   Crypto Provider   -   this is the bean to set the search encryption provider to null -->
	<bean id="searchCryptoProvider" class="de.comlineag.snc.crypto.NullCryptoProvider"> </bean>
	
	<!-- BASE64 Crypto Provider   -   this is the bean to set the data encryption provider to Base64 --> 
	<!-- <bean id="searchCryptoProvider" class="de.comlineag.snc.crypto.Base64CryptoProvider"> </bean> -->
	
	<!-- DES    Crypto Provider   -   this is the bean to set the data encryption provider to DES -->
	<!-- <bean id="searchCryptoProvider" class="de.comlineag.snc.crypto.DesCryptoProvider"> 
			<property name="initialVector"dfhjhgcfngcfhcecf4tcdgc5vtrgvhtdzvcgcdbzvt5cxhvxtycsvtsctyvzs5zcc5zzvhcdht></property>
		</bean>
	-->
	
	<!-- 3DES   Crypto Provider   -   this is the bean to set the data encryption provider to Triple DES -->
	<!-- <bean id="searchCryptoProvider" class="de.comlineag.snc.crypto.Des3CryptoProvider"> </bean> -->
	
	<!-- AES    Crypto Provider   -   this is the bean to set the data encryption provider to AES -->
	<!-- <bean id="searchCryptoProvider" class="de.comlineag.snc.crypto.AesCryptoProvider"> </bean> -->
	
	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
	     END OF CRYPTO SECTION - END OF CRYPTO SECTION - END OF CRYPTO SECTION - END O
	     - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->
	
	
	
	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
	     NO NEED TO CHANGE ANYTHING BELOW THIS LINE - IF YOU DO CHANGE ANYTHING BE VERY
	     CAREFUL WHAT YOU DO HERE - IF YOU CHANGE ANYTHING IT MIGHT KILL THE CONNECTOR! 
	     - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->
	<!-- F S    C R A W L E R    (IN DEVELOPMENT)		-->
	<bean name="FsCrawlerDetail"
		class="org.springframework.scheduling.quartz.JobDetailFactoryBean">
		<property name="jobClass" value="de.comlineag.snc.job.FsCrawler" />
		<!-- <property name="concurrent" value="false" /> -->
		<property name="durability" value="true" />
		<property name="jobDataAsMap">
			<map>
				<entry key="fileNamePattern" value=".*_fail.json" />
				<!-- make absolutely sure, that these entries are in sync with SNC_Runtime_Configuration.xml -->
				<entry key="StoragePath" value="storage"/>
				<entry key="JsonBackupStoragePath" value="json"/>
				<entry key="ProcessedJsonBackupStoragePath" value="processedJson"/>
				<entry key="InvalidJsonBackupStoragePath" value="invalidJson"/>
				<entry key="MoveOrDeleteProcessedJsonFiles" value="move"/>
			</map>
		</property>
	</bean>
	<bean id="FsCrawlerTrigger"
		class="org.springframework.scheduling.quartz.SimpleTriggerFactoryBean">
		<property name="jobDetail" ref="FsCrawlerDetail" />
		<!-- <property name="startDelay" value="30000" /> -->
		<property name="startDelay" value="300" />
		<property name="repeatInterval" value="180000" />
	</bean>
	
	<!-- R U N T I M E    S E T T I N G S -->
	<bean name="RuntimeConfigurationDetail"
		class="org.springframework.scheduling.quartz.JobDetailFactoryBean">
		<property name="jobClass" value="de.comlineag.snc.appstate.RuntimeConfiguration" />
		<property name="Durability" value="true"/>
		<!-- <property name="Concurrent" value="false" /> --> 
		<!-- <property name="Singleton" value="true"/> -->
		<property name="jobDataAsMap">
			<map>
				<entry key="configFile" value="webapp/WEB-INF/SNC_Runtime_Configuration.xml" />
			</map>
		</property>
	</bean>
	<bean id="RuntimeConfigurationTrigger"
		class="org.springframework.scheduling.quartz.SimpleTriggerFactoryBean">
		<property name="jobDetail" ref="RuntimeConfigurationDetail" />
		<property name="startDelay" value="1" />
		<property name="repeatInterval" value="120000" />
	</bean>
	
	
	<!-- Quartz scheduler properties 
		 these entries are needed for the JMX Access to the Job Factory, 
		 so that the job state can be monitored by the administration website -->
	<bean id="quartzScheduler" class="org.springframework.scheduling.quartz.SchedulerFactoryBean">
		<property name="quartzProperties"> 
			<util:properties>
				<!-- Must be set to true, otherwise the Quartz scheduler is not registered in the JMX server. -->
				<prop key="org.quartz.scheduler.jmx.export">true</prop>
				<!-- JMX object name the Quartz scheduler is registered under in the JMX server. -->
				<prop key="org.quartz.scheduler.jmx.objectName"> quartz:type=QuartzScheduler,name=SNC</prop>
			</util:properties>
  		</property>
	</bean>
</beans>
